{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from math import sqrt\n",
    "from tensorflow.keras.utils  import plot_model\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "load_address = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\trajectory_demo\\\\datas\\\\'\n",
    "n_in_h = 7\n",
    "n_out_h = 1\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Lambda, dot, Activation, concatenate\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "def change_shape(data, input_n, output_n):\n",
    "    traject = []#Create empty list of tracks\n",
    "    n_in_h = input_n\n",
    "    n_out_h = output_n\n",
    "    for k in range(0, len(data) - (n_in_h + n_out_h), (n_in_h + n_out_h)):\n",
    "        a = []\n",
    "        for j in range(k, k + (n_in_h + n_out_h)):#Loop from the kth position to k+8\n",
    "            b = []#Create empty list\n",
    "            if j == k:#If the first\n",
    "                for i in range(3):#Add x and y to b\n",
    "                    b.append(data[k][i])\n",
    "            else:#If not the first\n",
    "                for i in range(3):#Add x and y to b\n",
    "                    b.append(data[j][i])\n",
    "            a.append(b)#Put each b into a\n",
    "        traject.append(a)#Put a in the empty list of trajectories\n",
    "    len_in = (len(traject) * 80) // 100#Use 4/5 as the training set\n",
    "    train = traject[:len_in]\n",
    "    test = traject[len_in:]\n",
    "    #shape(None,(in+out),3)\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(train)\n",
    "\n",
    "    # Split the data into x_train, y_train, x_test and y_test\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(0, len(train)):\n",
    "        temp = []\n",
    "        for k in range(n_in_h):\n",
    "            temp.append(train[i][k])\n",
    "        x_train.append(temp)\n",
    "    for i in range(0, len(train)):\n",
    "        temp = []\n",
    "        for k in range(n_in_h, n_in_h + n_out_h):#（7.8）\n",
    "            temp.append(train[i][k])\n",
    "        y_train.append(temp)\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(0, len(test)):\n",
    "        temp = []\n",
    "        for k in range(n_in_h):\n",
    "            temp.append(test[i][k])\n",
    "        x_test.append(temp)\n",
    "    for i in range(0, len(test)):\n",
    "        temp = []\n",
    "        for k in range(n_in_h, n_in_h + n_out_h):\n",
    "            temp.append(test[i][k])\n",
    "        y_test.append(temp)\n",
    "\n",
    "    # Convert the data into numpy array\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def change_to_random_data(data):\n",
    "    data = data.reshape(-1,data.shape[1]*data.shape[2])\n",
    "    return data\n",
    "\n",
    "def change_back(data,size,n):\n",
    "    data = data.reshape(-1,size,n)\n",
    "    return data\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 2.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def __call__(self, hidden_states):\n",
    "        hidden_size = int(hidden_states.shape[2])\n",
    "        # Inside dense layer\n",
    "        #              hidden_states            dot               W            =>           score_first_part\n",
    "        # (batch_size, time_steps, hidden_size) dot (hidden_size, hidden_size) => (batch_size, time_steps, hidden_size)\n",
    "        # W is the trainable weight matrix of attention Luong's multiplicative style score\n",
    "        score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec')(hidden_states)\n",
    "        #            score_first_part           dot        last_hidden_state     => attention_weights\n",
    "        # (batch_size, time_steps, hidden_size) dot   (batch_size, hidden_size)  => (batch_size, time_steps)\n",
    "        h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(hidden_states)\n",
    "        score = dot([score_first_part, h_t], [2, 1], name='attention_score')\n",
    "        attention_weights = Activation('softmax', name='attention_weight')(score)\n",
    "        # (batch_size, time_steps, hidden_size) dot (batch_size, time_steps) => (batch_size, hidden_size)\n",
    "        context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector')\n",
    "        pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
    "        attention_vector = Dense(100, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n",
    "        return attention_vector\n",
    "\n",
    "attention = Attention(name='attention_weight')\n",
    "#steps = n//2\n",
    "#--------------------Encoder--------------------#\n",
    "visible = tf.keras.layers.Input(shape=(n_in_h,3))\n",
    "encoder = tf.keras.layers.LSTM(100, activation='relu', return_sequences=True)(visible)\n",
    "# define reconstruction decoder\n",
    "decoder1 = tf.keras.layers.LSTM(100, activation='relu', return_sequences=True)(encoder)\n",
    "decoder1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2))(decoder1)\n",
    "encoder = attention(encoder)\n",
    "# define prediction decoder\n",
    "cells = tf.expand_dims(encoder,1)\n",
    "decoder2 = tf.keras.layers.LSTM(100, activation='relu', return_sequences=True)(cells)\n",
    "decoder2 = tf.keras.layers.Dense(2*n_out_h)(decoder2)\n",
    "decoder2 = tf.reshape(decoder2, shape=[-1,n_out_h,2])\n",
    "model = tf.keras.models.Model(inputs=[visible],\n",
    "                              outputs=[decoder1,decoder2])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 7, 3)\n",
      "(178, 1, 3)\n",
      "(45, 7, 3)\n",
      "(45, 1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nplt.plot(test_pre_encoder[:,:,0])\\nplt.plot(y_test[:,:,0])\\nplt.plot(test_pre_encoder[:,:,1])\\nplt.plot(y_test[:,:,1])\\nplt.xlabel(\\'Every step of one seal\\') #x轴\\nplt.ylabel(\\'Moving distance per hour (meter)\\') #y轴\\nplt.savefig(\"xyonesealencoder4.png\", dpi=500, bbox_inches=\\'tight\\')\\n\\nplt.plot(y_pre)\\nplt.plot(y_ture)\\nplt.savefig(\"diastance_one_seal_encoder.png\", dpi=2000, bbox_inches=\\'tight\\')\\n'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_encoder = []\n",
    "mse_encoder = []\n",
    "rmse_encoder = []\n",
    "mape_encoder = []\n",
    "smape_encoder = []\n",
    "r2_encoder = []\n",
    "\n",
    "data = np.load(load_address+\"0.npy\")\n",
    "\n",
    "mean = np.mean(data,axis=0)#Calculate the mean of each column\n",
    "std = np.std(data, axis=0) #Calculate the standard deviation of each column\n",
    "\n",
    "#-----------------Normalized-------------------#\n",
    "data[:,0] = (data[:,0] - mean[0]) / std[0]\n",
    "data[:,1] = (data[:,1] - mean[1]) / std[1]\n",
    "data[:,2] = (data[:,2] - mean[2]) / std[2]\n",
    "#print(data[-1:,:])\n",
    "\n",
    "#-----------------calculate data-----------------#\n",
    "x_train,y_train,x_test,y_test = change_shape(data,n_in_h ,n_out_h)\n",
    "\n",
    "#-------------------encoder------------------#\n",
    "model.fit(x_train,[x_train[:,:,:2],y_train[:,:,:2]],epochs=500,batch_size=1000,verbose=0)\n",
    "x_pre_encoder,test_pre_encoder = model.predict(x_test, verbose=0)\n",
    "\n",
    "#-----------------Denormalization-----------------#\n",
    "test_pre_encoder[:,:,:] = test_pre_encoder[:,:,:] * std[:2] + mean[:2]\n",
    "y_test[:,:,:2] = y_test[:,:,:2] * std[:2] + mean[:2]\n",
    "\n",
    "y_pre =  np.sqrt(test_pre_encoder[:,:,0]**2+test_pre_encoder[:,:,1]**2)\n",
    "y_ture = np.sqrt(y_test[:,:,0]**2+y_test[:,:,1]**2)\n",
    "\n",
    "\n",
    "\n",
    "mae_encoder.append(mae(y_ture,y_pre))\n",
    "mse_encoder.append(mse(y_ture,y_pre))\n",
    "rmse_encoder.append(np.sqrt(mse(y_ture,y_pre)))\n",
    "mape_encoder.append(mape(y_ture,y_pre))\n",
    "smape_encoder.append(smape(y_ture,y_pre))\n",
    "r2_encoder.append(r2_score(y_ture,y_pre))\n",
    "\n",
    "mae_encoder = pd.DataFrame(mae_encoder)\n",
    "mse_encoder = pd.DataFrame(mse_encoder)\n",
    "rmse_encoder = pd.DataFrame(rmse_encoder)\n",
    "mape_encoder = pd.DataFrame(mape_encoder)\n",
    "smape_encoder = pd.DataFrame(smape_encoder)\n",
    "r2_encoder = pd.DataFrame(r2_encoder)\n",
    "evaluate = pd.concat([mae_encoder,mse_encoder,rmse_encoder,mape_encoder,smape_encoder,r2_encoder],axis=1)\n",
    "evaluate.to_csv(load_address+\"LSTM_encoder_attention_evalute_{0}_{1}.csv\".format(n_in_h,n_out_h))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}